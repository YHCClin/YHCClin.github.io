<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.0.0-rc.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.0.0-rc.0" type="image/png" sizes="32x32"><meta name="description" content="如何让网络可以学习       上一篇文章中的神经网络还没有学习能力，这好比如说该网络只接收外部输入并输出结果，却没有反馈机制没有对结果进行正确性分析，让我们以小明与老师之间的对话来比喻这种情况：">
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="人工神经网络学习笔记（1）">
<meta property="og:url" content="https://www.ccyh.xyz/p/5972.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="如何让网络可以学习       上一篇文章中的神经网络还没有学习能力，这好比如说该网络只接收外部输入并输出结果，却没有反馈机制没有对结果进行正确性分析，让我们以小明与老师之间的对话来比喻这种情况：">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023656961.png">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E6%AF%94%E8%AE%B0%EF%BC%881%EF%BC%89/20190603111024704.png">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E6%AF%94%E8%AE%B0%EF%BC%881%EF%BC%89/20190603113735974.png">
<meta property="og:updated_time" content="2020-03-23T04:59:32.937Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工神经网络学习笔记（1）">
<meta name="twitter:description" content="如何让网络可以学习       上一篇文章中的神经网络还没有学习能力，这好比如说该网络只接收外部输入并输出结果，却没有反馈机制没有对结果进行正确性分析，让我们以小明与老师之间的对话来比喻这种情况：">
<meta name="twitter:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023656961.png"><meta name="keywords" content="Liam, Liam's Blog"><meta name="description" content="Algorithms"><title>人工神经网络学习笔记（1）</title><link ref="canonical" href="/p/5972.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.0.0-rc.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Liam's Blog</div><div class="header-banner-info__subtitle">Liam's blog</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">人工神经网络学习笔记（1）</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2019-06-03</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2020-03-23</span></span></div></header><div class="post-body">
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><h3 id="如何让网络可以学习">
          <a href="#如何让网络可以学习" class="heading-link"><i class="fas fa-link"></i></a>如何让网络可以学习</h3>
      <p>上一篇文章中的神经网络还没有学习能力，这好比如说该网络只接收外部输入并输出结果，却没有反馈机制没有对结果进行正确性分析，让我们以小明与老师之间的对话来比喻这种情况：<br><a id="more"></a></p>
<ul>
<li>老师：1+1=？</li>
<li>小明：6</li>
<li>老师：1+2=？</li>
<li>小明：2</li>
<li>…</li>
</ul>
<p>可以发现，当小明给出答案后老师并没有给于他反馈。因此小明可能某一次猜中了正确答案，但只是凑巧而已，他不具备学习能力。<br>现在让老师给点反馈：</p>
<ul>
<li>老师：1+5=？</li>
<li>小明：4</li>
<li>老师：少了</li>
<li>小明：5</li>
<li>老师：少了</li>
<li>小明：6</li>
<li>老师：正确，你真棒！</li>
</ul>
<p>这样子，小明学会了1+5=6.<br><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023656961.png" alt="三层神经网络"><br>我们的神经网络也需要具备这样的学习能力。<br>也就是说，当网络输出错误的结果时要有一个改变下一次输出的机制。想要改变输出，可以改变哪些量呢？<br>观察输出函数：<br>$$<br>O_{output}=<br>\left[<br>\begin{matrix}<br>Sig(\sum_{j=1}^{3}{w_{j,1}\cdot i_{oj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,2}\cdot i_{oj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,3}\cdot i_{oj}}) \\<br>\end{matrix}<br>\right]=\left[\begin{matrix}o_1\\o_2\\o_3\end{matrix}\right]<br>$$<br>不难发现，输出值与以下参数有关：</p>
<ol>
<li>SigMoid函数</li>
<li>链接权重</li>
<li>输入值</li>
</ol>
<p>显然，我们不可能去左右网络的输入值，因为那是网络要求解的问题，不可能以改变问题的方式改变答案。那么改变激活函数sig如何？这太麻烦了，试想那么多的神经元每一个都不同的激活函数会对运算造成大麻烦，将无法采用简洁的矩阵运算。<br>因此，<strong>改变链接权重</strong>会是一个好办法。</p>
<hr>

        <h3 id="学习能力的养成">
          <a href="#学习能力的养成" class="heading-link"><i class="fas fa-link"></i></a>学习能力的养成</h3>
      <p>我们已经知道可以通过改变链接权重来改变网络的输出值，使其符合预期。那么问题又来了：</p>
<ol>
<li>改变权重的依据是什么？</li>
<li>如何改变？</li>
<li>改变的幅度多大合适？</li>
</ol>
<hr>

        <h4 id="改变的依据">
          <a href="#改变的依据" class="heading-link"><i class="fas fa-link"></i></a>改变的依据</h4>
      <p>改变权重的目的是让输出值与期望值越接近越好（误差值越小越好），因此误差就是依据。所谓误差就是期望值与网络输出值的差：<br>$$<br>E=t-o<br>$$<br>我们知道输出层的误差为：$E_o=t_n-o_n$，但是其他层结点的误差是不知道的，因为其他层并没有一个输出期望值$t_n$。<br>不难发现，最终输出层造成的误差是所有层共同作用的结果，所以可以将总误差分摊给其他层。</p>

        <h5 id="误差的反向传播">
          <a href="#误差的反向传播" class="heading-link"><i class="fas fa-link"></i></a>误差的反向传播</h5>
      <p><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E6%AF%94%E8%AE%B0%EF%BC%881%EF%BC%89/20190603111024704.png" alt="单个神经元的误差分配"></p>
<hr>
<p>如上图误差为$e_1$，因为链接权重越大说明对该误差的影响越大，因此以链接权重来决定每条链路所分摊误差的大小：<br>$$<br>e_{w_{1,1}}=\frac{w_{1,1}}{w_{1,1}+w_{2,1}}\cdot e_1<br>$$<br>$$<br>e_{w_{2,1}}=\frac{w_{2,1}}{w_{1,1}+w_{2,1}}\cdot e_1<br>$$<br><strong>反向传播误差到更多层中：</strong><br><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E6%AF%94%E8%AE%B0%EF%BC%881%EF%BC%89/20190603113735974.png" alt="误差的反向传播"><br>隐藏层结点的误差值：<br>$$<br>e_{h1}=\frac{w_{1,1}}{w_{1,1}+w_{2,1}}\cdot e_{o1}+\frac{w_{1,2}}{w_{1,2}+w_{2,2}}\cdot e_{o2}<br>$$</p>
<hr>

        <h5 id="使用矩阵乘法简化误差反向传播">
          <a href="#使用矩阵乘法简化误差反向传播" class="heading-link"><i class="fas fa-link"></i></a>使用矩阵乘法简化误差反向传播</h5>
      <ol>
<li>误差向量：<br>$$<br>error_{output}=<br>\left(<br>\begin{matrix}<br>e_1 \\<br>e_2<br>\end{matrix}<br>\right)<br>$$</li>
<li>隐藏层误差：<br>$$<br>error_{hidden}=<br>\left(<br>\begin{matrix}<br>\frac{w_{1,1}}{w_{1,1}+w_{2,1}} &amp; \frac{w_{1,2}}{w_{1,2}+w_{2,2}} \\<br>\\<br>\frac{w_{2,1}}{w_{1,1}+w_{2,1}} &amp; \frac{w_{2,2}}{w_{1,2}+w_{2,2}}<br>\end{matrix}<br>\right) \cdot \left(\begin{matrix}e_1 \\ e_2 \end{matrix} \right)=\left(\begin{matrix}e_{h1}\\e_{h2}\end{matrix}\right)<br>$$<br>上述矩阵乘法太过复杂，无法通过简单的矩阵运算求解。观察上式可知，最重要的事情是输出误差链接权重$w_{j,k}$的乘法。较大的权重携带较大的误差给隐藏层，这些分数的分母是一种归一化因子。如果我们忽略掉这个因子，我们仅仅只是失去了后馈误差的真实值大小，但并没有失去其表示的真正含义（影响力）,也就是说反馈误差始终是以链接权重的强度来分配的。因此上式可以简化为：<br>$$<br>error_{hidden}=<br>\left(<br>\begin{matrix}<br>w_{1,1} &amp; w_{1,2} \\<br>w_{2,1} &amp; w_{2,2}<br>\end{matrix}<br>\right)\cdot \left(\begin{matrix}e_1\\ e_2\end{matrix}\right)=\left(\begin{matrix}e_{h1}\\e_{h2}\end{matrix}\right)<br>$$<br>不难发现，隐藏层至输出层的链接权重矩阵$W_{hidden\rightarrow output}$为:<br>$$<br>W_{hidden\rightarrow output}=<br>\left(<br>\begin{matrix}<br>w_{1,1} &amp; w_{2,1} \\<br>w_{1,2} &amp; w_{2,2}<br>\end{matrix}<br>\right)=\left(<br>\begin{matrix}<br>w_{1,1} &amp; w_{1,2} \\<br>w_{2,1} &amp; w_{2,2}<br>\end{matrix}<br>\right)^T<br>$$<br>因此：<br>$$<br>error_{hidden}=W_{hidden\rightarrow output}^T\cdot error_{output}=<br>\left(<br>\begin{matrix}<br>w_{1,1} &amp; w_{2,1} \\<br>w_{1,2} &amp; w_{2,2}<br>\end{matrix}<br>\right)^T\cdot \left(\begin{matrix}e_1\\ e_2\end{matrix}\right)=\left(\begin{matrix}e_{h1}\\e_{h2}\end{matrix}\right)<br>$$<br>到此我们得到了用矩阵来传播误差的算法：<br>$$<br>error_{hidden}=W_{hidden\rightarrow output}^T\cdot error_{output}<br>$$</li>
</ol>
<hr>
<p>到此，我们已经做了大量的工作了。我们计算出了所有层的误差，接下来的工作就是根据误差来调整链接权重了。</p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://www.ccyh.xyz">Liam</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://www.ccyh.xyz/p/5972.html">https://www.ccyh.xyz/p/5972.html</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://www.ccyh.xyz/tags/ML/">ML</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/p/1d72.html"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">人工神经网络学习笔记（2）</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/p/a573.html"><span class="paginator-prev__text">人工神经网络学习笔记（0）</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#如何让网络可以学习"><span class="toc-number">1.</span> <span class="toc-text">
          如何让网络可以学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习能力的养成"><span class="toc-number">2.</span> <span class="toc-text">
          学习能力的养成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#改变的依据"><span class="toc-number">2.1.</span> <span class="toc-text">
          改变的依据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#误差的反向传播"><span class="toc-number">2.1.1.</span> <span class="toc-text">
          误差的反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用矩阵乘法简化误差反向传播"><span class="toc-number">2.1.2.</span> <span class="toc-text">
          使用矩阵乘法简化误差反向传播</span></a></li></ol></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">47</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">11</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">21</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Liam</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v3.8.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.0.0-rc.0</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zindex="-1"></script><script src="/js/utils.js?v=2.0.0-rc.0"></script><script src="/js/stun-boot.js?v=2.0.0-rc.0"></script><script src="/js/scroll.js?v=2.0.0-rc.0"></script><script src="/js/header.js?v=2.0.0-rc.0"></script><script src="/js/sidebar.js?v=2.0.0-rc.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>