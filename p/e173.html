<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.0.0-rc.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.0.0-rc.0" type="image/png" sizes="32x32"><meta name="description" content="Python-numpy编码实现人工神经网络        前面的几篇文章我们熟悉了人工神经网络的数学原理及其推导过程，但有道是‘纸上得来终觉浅’，是时候将理论变为现实了。现在我们将应用Python语言以及其强大的扩充程序库Numpy来编写一个简单的神经网络。">
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="人工神经网络学习笔记（3）">
<meta property="og:url" content="https://www.ccyh.xyz/p/e173.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="Python-numpy编码实现人工神经网络        前面的几篇文章我们熟悉了人工神经网络的数学原理及其推导过程，但有道是‘纸上得来终觉浅’，是时候将理论变为现实了。现在我们将应用Python语言以及其强大的扩充程序库Numpy来编写一个简单的神经网络。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607010119916.png">
<meta property="og:image" content="https://www.ccyh.xyz/人工神经网络学习笔记（3）/20190607015526334.png">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607011216578.png">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607011510082.png">
<meta property="og:updated_time" content="2020-03-23T04:59:32.938Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工神经网络学习笔记（3）">
<meta name="twitter:description" content="Python-numpy编码实现人工神经网络        前面的几篇文章我们熟悉了人工神经网络的数学原理及其推导过程，但有道是‘纸上得来终觉浅’，是时候将理论变为现实了。现在我们将应用Python语言以及其强大的扩充程序库Numpy来编写一个简单的神经网络。">
<meta name="twitter:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607010119916.png"><meta name="keywords" content="Liam, Liam's Blog"><meta name="description" content="Algorithms"><title>人工神经网络学习笔记（3）</title><link ref="canonical" href="/p/e173.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.0.0-rc.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Liam's Blog</div><div class="header-banner-info__subtitle">Liam's blog</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">人工神经网络学习笔记（3）</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2019-06-07</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2020-03-23</span></span></div></header><div class="post-body">
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><h3 id="Python-numpy编码实现人工神经网络">
          <a href="#Python-numpy编码实现人工神经网络" class="heading-link"><i class="fas fa-link"></i></a>Python-numpy编码实现人工神经网络</h3>
      <hr>
<p>前面的几篇文章我们熟悉了人工神经网络的数学原理及其推导过程，但有道是‘纸上得来终觉浅’，是时候将理论变为现实了。现在我们将应用Python语言以及其强大的扩充程序库<span class="exturl"><a class="exturl__link" href="https://www.runoob.com/numpy/numpy-tutorial.html" target="_blank" rel="noopener">Numpy</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>来编写一个简单的神经网络。<br><a id="more"></a></p>
<hr>

        <h4 id="准备数据：">
          <a href="#准备数据：" class="heading-link"><i class="fas fa-link"></i></a>准备数据：</h4>
      <ul>
<li><strong>训练集and测试集：</strong><a href="git@github.com:makeyourownneuralnetwork/makeyourownneuralnetwork.git">Mnist手写数字数据集(复制git链接克隆)</a>MINST数据库是由米国机器学习大佬Yann提供的手写数字数据库文件，其官方下载地址<span class="exturl"><a class="exturl__link" href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">Download Mnist</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>。该数据集将会是神经网络的输入信号。</li>
</ul>
<p>每一张图片像素都为$28\times 28$,因此可作为一个$784\times 1$的向量传入神经网络。</p>
<div align="center"><br><br><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607010119916.png" alt="单个图片"><br><img src="/人工神经网络学习笔记（3）/20190607015526334.png" alt=""><br><br></div>

<ul>
<li>初始花链接权重矩阵：使用正态概率分布采样权重，平均值为0，标准方差为结点传入链接数目的开方，即$\frac{1}{\sqrt{inputconnects}}$</li>
</ul>
<hr>

        <h4 id="编码实现">
          <a href="#编码实现" class="heading-link"><i class="fas fa-link"></i></a>编码实现</h4>
      <p>下面的代码实现了一个双隐层的神经网络，但是它的表现并不好（最起码在Mnist数据集的表现上差强人意），我训练了5个小时（5世代）也只能达到%96.54的准确率。相比而言当隐层的神经网络在Mnist数据集上的表现更好，三个小时（5世代）可以达到%97.34的准确率。你可以注释掉下面的部分代码将其退回到单隐层结构甚至加到三隐层结构。虽然代码写的很乱但代码中每一句都有详细的注释，别介意哈哈哈。<br>包含两个源代码文件：</p>
<ul>
<li>neural_network.py 包含神经网络主类用于训练神经网络</li>
<li>network_test.py 用于测试神经网络</li>
</ul>
<hr>
 <font size="3px" face="黑体" color="green"> neural_network.py </font>

<figure class="highlight python"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.special</span><br><span class="line"><span class="keyword">import</span> scipy.ndimage.interpolation</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> progressbar</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> anim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 神经网络类定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">neuralNetwork</span>:</span></span><br><span class="line">	<span class="comment"># 初始化神经网络</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,inputnodes,hiddennodes,hiddennodes_2,outputnodes,learningrate)</span>:</span></span><br><span class="line">		<span class="comment"># 设置神经网络的输入层、隐藏层、输出层、的结点数和学习率</span></span><br><span class="line">		self.inodes = inputnodes</span><br><span class="line">		self.hnodes = hiddennodes                <span class="comment"># 第一隐藏层结点数</span></span><br><span class="line">		self.hnodes_2 = hiddennodes_2            <span class="comment"># 第二隐藏层结点数</span></span><br><span class="line">		<span class="comment">#self.hnodes_3 = hiddennodes_3            # 第三隐藏层结点数</span></span><br><span class="line">		self.onodes = outputnodes</span><br><span class="line">		<span class="comment"># 学习率</span></span><br><span class="line">		self.lr = learningrate</span><br><span class="line">		</span><br><span class="line">		<span class="comment"># （常规版）链接权重矩阵,随机权重在-0.5至0.5之间（三层神经网络）</span></span><br><span class="line">		self.wih = (numpy.random.rand(hiddennodes,inputnodes)<span class="number">-0.5</span>)            </span><br><span class="line">		self.who = (numpy.random.rand(outputnodes,hiddennodes)<span class="number">-0.5</span>)           </span><br><span class="line">		<span class="comment"># （进阶版）链接权重矩阵,随机权重在-0.5至0.5之间（三层神经网络）</span></span><br><span class="line">		self.wih_ = numpy.random.normal(<span class="number">0.0</span>,pow(self.hnodes,<span class="number">-0.5</span>),(hiddennodes,inputnodes))          <span class="comment"># 输入层到第一隐藏层权重矩阵</span></span><br><span class="line">		self.wh12_ = numpy.random.normal(<span class="number">0.0</span>,pow(self.hnodes_2,<span class="number">0.5</span>),(hiddennodes_2,hiddennodes))     <span class="comment"># 第一隐藏层到第二隐藏层权重矩阵</span></span><br><span class="line">		<span class="comment">#self.wh23_ = numpy.random.normal(0.0,pow(self.hnodes_3,0.5),(hiddennodes_3,hiddennodes_2))   # 第二隐藏层到第三隐藏层权重矩阵</span></span><br><span class="line">		self.who_ = numpy.random.normal(<span class="number">0.0</span>,pow(self.onodes,<span class="number">-0.5</span>),(outputnodes,hiddennodes_2))         <span class="comment"># 第三隐藏层到输出层权重矩阵</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">#定义激活函数，由scipy库提供</span></span><br><span class="line">		self.activation_function = <span class="keyword">lambda</span> x : scipy.special.expit(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 训练神经网络</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self,inputs_list,targets_list)</span>:</span></span><br><span class="line">		<span class="comment"># 将输入信号列表和目标信号列表转换成列向量</span></span><br><span class="line">		inputs = numpy.array(inputs_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">		targets = numpy.array(targets_list,ndmin=<span class="number">2</span>).T</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 第一隐藏层的输入信号：</span></span><br><span class="line">		hidden_inputs = numpy.dot(self.wih_,inputs)</span><br><span class="line">		<span class="comment"># 第一隐藏层的输出信号（激活函数作用）：</span></span><br><span class="line">		hidden_outputs = self.activation_function(hidden_inputs)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 第二隐藏层的输入信号:</span></span><br><span class="line">		hidden_inputs_2 = numpy.dot(self.wh12_,hidden_outputs)</span><br><span class="line">		<span class="comment"># 第二层隐藏层的输出信号：</span></span><br><span class="line">		hidden_outputs_2 = self.activation_function(hidden_inputs_2)</span><br><span class="line">		<span class="string">'''</span></span><br><span class="line"><span class="string">		# 第三隐藏层的输入信号：</span></span><br><span class="line"><span class="string">		hidden_inputs_3 = numpy.dot(self.wh23_,hidden_outputs_2)</span></span><br><span class="line"><span class="string">		# 第三隐藏层的输出信号：</span></span><br><span class="line"><span class="string">		hidden_outputs_3 = self.activation_function(hidden_inputs_3)</span></span><br><span class="line"><span class="string">		'''</span></span><br><span class="line">		<span class="comment"># 输出层的输入信号：</span></span><br><span class="line">		final_inputs = numpy.dot(self.who_,hidden_outputs_2)</span><br><span class="line">		<span class="comment"># 输出层的输出信号：</span></span><br><span class="line">		final_outputs = self.activation_function(final_inputs)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 计算输出层误差向量</span></span><br><span class="line">		output_errors = targets - final_outputs</span><br><span class="line">		<span class="comment"># 计算第三隐藏层误差向量</span></span><br><span class="line">		<span class="comment">#hidden_errors_3 = numpy.dot(self.who_.T,output_errors)</span></span><br><span class="line">		<span class="comment"># 计算第二隐藏层的误差向量</span></span><br><span class="line">		hidden_errors_2 = numpy.dot(self.who_.T,output_errors)</span><br><span class="line">		<span class="comment"># 计算第一隐藏层的误差向量</span></span><br><span class="line">		hidden_errors = numpy.dot(self.wh12_.T,hidden_errors_2)</span><br><span class="line"></span><br><span class="line">		<span class="string">''' 优化链接权重值 '''</span></span><br><span class="line">		<span class="comment"># 第三隐藏层与输出层间的链接权重优化</span></span><br><span class="line">		<span class="comment">#self.who_ += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)),numpy.transpose(hidden_outputs_3))</span></span><br><span class="line">		<span class="comment"># 第二隐藏层与第三隐藏层间的链接权重优化</span></span><br><span class="line">		self.who_ += self.lr * numpy.dot((output_errors * final_outputs * (<span class="number">1.0</span> - final_outputs)),numpy.transpose(hidden_outputs_2))</span><br><span class="line">		<span class="comment"># 第一隐藏层与第二隐藏层间的链接权重优化</span></span><br><span class="line">		self.wh12_ += self.lr * numpy.dot((hidden_errors_2 * hidden_outputs_2 * (<span class="number">1.0</span> - hidden_outputs_2)),numpy.transpose(hidden_outputs))</span><br><span class="line">		<span class="comment"># 输入层与第一隐藏层间的链接权重优化</span></span><br><span class="line">		self.wih_ += self.lr * numpy.dot((hidden_errors * hidden_outputs * (<span class="number">1.0</span> - hidden_outputs)),numpy.transpose(inputs))</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		<span class="comment">#return self.query(inputs_list)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 查询</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">query</span><span class="params">(self,inputs_list)</span>:</span></span><br><span class="line">		<span class="comment"># 将输入列表转成numpy向量对象并转置为列向量</span></span><br><span class="line">		inputs = numpy.array(inputs_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">		<span class="comment"># 第一隐藏层结点的输入信号：权重矩阵与输入信号向量的乘积</span></span><br><span class="line">		self.hidden_inputs = numpy.dot(self.wih_,inputs)</span><br><span class="line">		<span class="comment"># 第一隐藏层结点的输出信号：经过S函数的加权求和值</span></span><br><span class="line">		self.hidden_outputs = self.activation_function(self.hidden_inputs)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 第二隐藏层的输入信号:</span></span><br><span class="line">		self.hidden_inputs_2 = numpy.dot(self.wh12_,self.hidden_outputs)</span><br><span class="line">		<span class="comment"># 第二层隐藏层的输出信号：</span></span><br><span class="line">		self.hidden_outputs_2 = self.activation_function(self.hidden_inputs_2)</span><br><span class="line">		<span class="string">'''</span></span><br><span class="line"><span class="string">		# 第三隐藏层的输入信号：</span></span><br><span class="line"><span class="string">		self.hidden_inputs_3 = numpy.dot(self.wh23_,self.hidden_outputs_2)</span></span><br><span class="line"><span class="string">		# 第三隐藏层的输出信号：</span></span><br><span class="line"><span class="string">		self.hidden_outputs_3 = self.activation_function(self.hidden_inputs_3)</span></span><br><span class="line"><span class="string">		'''</span></span><br><span class="line">		<span class="comment"># 输出层结点的输入信号：</span></span><br><span class="line">		self.final_inputs = numpy.dot(self.who_,self.hidden_outputs_2)</span><br><span class="line">		<span class="comment"># 输出层结点的最终输出信号：</span></span><br><span class="line">		self.final_outputs = self.activation_function(self.final_inputs)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># 返回最终输出信号</span></span><br><span class="line">		<span class="keyword">return</span> self.final_outputs</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(Network,test_dataset_name)</span>:</span></span><br><span class="line">	Network.wih_ = numpy.loadtxt(<span class="string">'wih_file.csv'</span>)</span><br><span class="line">	Network.wh12_ = numpy.loadtxt(<span class="string">'wh12_file.csv'</span>)</span><br><span class="line">	<span class="comment">#Network.wh23_ = numpy.loadtxt('wh23_file.csv')</span></span><br><span class="line">	Network.who_ = numpy.loadtxt(<span class="string">'who_file.csv'</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 准备测试数据</span></span><br><span class="line">	test_data_file = open(test_dataset_name,<span class="string">'r'</span>)</span><br><span class="line">	test_data_list = test_data_file.readlines()</span><br><span class="line">	test_data_file.close()</span><br><span class="line"></span><br><span class="line">	print(<span class="string">'\n'</span>)</span><br><span class="line">	print(<span class="string">"Testing...\n"</span>)</span><br><span class="line">	<span class="comment"># 统计</span></span><br><span class="line">	correct_test = <span class="number">0</span></span><br><span class="line">	all_test = <span class="number">0</span></span><br><span class="line">	correct = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">	num_counter = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment">#测试进度条</span></span><br><span class="line">	p_test = progressbar.ProgressBar()</span><br><span class="line">	p_test.start(len(test_data_list))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 动画显示</span></span><br><span class="line">	<span class="comment">#plt.figure(1)</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> imag_list <span class="keyword">in</span> test_data_list:</span><br><span class="line">		all_values = imag_list.split(<span class="string">','</span>)</span><br><span class="line">		lable = int(all_values[<span class="number">0</span>])</span><br><span class="line">		scaled_input = (numpy.asfarray(all_values[<span class="number">1</span>:]) / <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span></span><br><span class="line">		imag_array = numpy.asfarray(scaled_input).reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">		<span class="string">'''</span></span><br><span class="line"><span class="string">		plt.imshow(imag_array,cmap='Greys',animated=True)</span></span><br><span class="line"><span class="string">		plt.draw()</span></span><br><span class="line"><span class="string">		plt.pause(0.00001)</span></span><br><span class="line"><span class="string">		'''</span></span><br><span class="line">		net_answer = Network.query(scaled_input).tolist().index(max(Network.final_outputs))</span><br><span class="line">		num_counter[lable] += <span class="number">1</span></span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> lable == int(net_answer):</span><br><span class="line">			correct_test += <span class="number">1</span></span><br><span class="line">			correct[lable] += <span class="number">1</span></span><br><span class="line">		p_test.update(all_test + <span class="number">1</span>)</span><br><span class="line">		all_test += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	p_test.finish()</span><br><span class="line">	print(<span class="string">"Finish Test.\n"</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 网络性能</span></span><br><span class="line">	performance = correct_test/all_test</span><br><span class="line">	Per_num_performance = []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">		<span class="comment"># 测试集可能不包含某些数字，故捕捉除以0异常</span></span><br><span class="line">		<span class="keyword">try</span>:</span><br><span class="line">			Per_num_performance.append(correct[i]/num_counter[i])</span><br><span class="line">		<span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">			Per_num_performance.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">	print(<span class="string">"The correctRate of per number： "</span>,Per_num_performance)</span><br><span class="line">	print(<span class="string">"Performance of the NeuralNetwork： "</span>,performance*<span class="number">100</span>)</span><br><span class="line">	<span class="keyword">return</span> performance</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络规模与学习率</span></span><br><span class="line">input_nodes = <span class="number">784</span></span><br><span class="line">hidden_nodes = <span class="number">700</span></span><br><span class="line">hidden_nodes_2 = <span class="number">700</span></span><br><span class="line"><span class="comment">#hidden_nodes_3 = 100</span></span><br><span class="line">output_nodes = <span class="number">10</span></span><br><span class="line">learningrate = <span class="number">0.0001</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 定义训练世代数</span></span><br><span class="line">	epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#创建神经网络实例</span></span><br><span class="line">	Net = neuralNetwork(input_nodes,hidden_nodes,hidden_nodes_2,output_nodes,learningrate)</span><br><span class="line"></span><br><span class="line">	<span class="comment">#plt.imshow(final_outputs,interpolation="nearest")</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 准备训练数据</span></span><br><span class="line">	data_file = open(<span class="string">"mnist_train.csv"</span>,<span class="string">'r'</span>)</span><br><span class="line">	data_list = data_file.readlines()</span><br><span class="line">	N_train = len(data_list)</span><br><span class="line">	data_file.close()</span><br><span class="line">	<span class="comment"># 动画显示</span></span><br><span class="line">	<span class="comment">#plt.figure(1)</span></span><br><span class="line"></span><br><span class="line">	print(<span class="string">"Training："</span>, epochs, <span class="string">"epochs..."</span>)</span><br><span class="line">	<span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">		<span class="comment"># 训练进度条</span></span><br><span class="line">		print(<span class="string">'\nThe '</span>+str(e+<span class="number">1</span>)+<span class="string">'th epoch trainning:\n'</span>)</span><br><span class="line">		p_train = progressbar.ProgressBar()</span><br><span class="line">		p_train.start(N_train)</span><br><span class="line">		i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> img_list <span class="keyword">in</span> data_list:</span><br><span class="line">			<span class="comment"># 以逗号分割记录</span></span><br><span class="line">			all_values = img_list.split(<span class="string">','</span>)</span><br><span class="line">			<span class="comment"># 将0-255映射到0.01-0.99</span></span><br><span class="line">			scaled_input = (numpy.asfarray(all_values[<span class="number">1</span>:]) / <span class="number">255.0</span> * <span class="number">0.99</span>) + <span class="number">0.01</span></span><br><span class="line">			imag_array = numpy.asfarray(scaled_input).reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">			<span class="comment">#plt.imshow(imag_array,cmap='Greys',animated=True)</span></span><br><span class="line">			<span class="comment">#plt.draw()</span></span><br><span class="line">			<span class="comment">#plt.pause(0.00001)</span></span><br><span class="line"></span><br><span class="line">			<span class="comment">#旋转图像生成新的训练集</span></span><br><span class="line">			input_plus_10imag = scipy.ndimage.interpolation.rotate(imag_array,<span class="number">10</span>,cval=<span class="number">0.01</span>,reshape=<span class="keyword">False</span>)</span><br><span class="line">			input_minus_10imag = scipy.ndimage.interpolation.rotate(imag_array,<span class="number">-10</span>,cval=<span class="number">0.01</span>,reshape=<span class="keyword">False</span>)</span><br><span class="line">			input_plus10 = input_plus_10imag.reshape((<span class="number">1</span>,<span class="number">784</span>))</span><br><span class="line">			input_minus10 = input_minus_10imag.reshape((<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">			<span class="comment"># 根据标签创建目标值向量</span></span><br><span class="line">			targets = numpy.zeros(output_nodes) + <span class="number">0.01</span></span><br><span class="line">			targets[int(all_values[<span class="number">0</span>])] = <span class="number">0.99</span></span><br><span class="line"></span><br><span class="line">			<span class="comment"># 用三个训练集训练神经网络</span></span><br><span class="line">			Net.train(scaled_input,targets)</span><br><span class="line">			Net.train(input_plus10,targets)</span><br><span class="line">			Net.train(input_minus10,targets)</span><br><span class="line"></span><br><span class="line">			<span class="comment">#time.sleep(0.01)</span></span><br><span class="line">			p_train.update(i+<span class="number">1</span>)</span><br><span class="line">			i+=<span class="number">1</span></span><br><span class="line">		p_train.finish()</span><br><span class="line">		</span><br><span class="line">	print(<span class="string">"\nTrainning finish.\n"</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将训练好的神经网络链接权重输出到csv文件中</span></span><br><span class="line">	numpy.savetxt(<span class="string">'wih_file.csv'</span>,Net.wih_,fmt=<span class="string">'%f'</span>)</span><br><span class="line">	numpy.savetxt(<span class="string">'wh12_file.csv'</span>,Net.wh12_,fmt=<span class="string">'%f'</span>)</span><br><span class="line">	<span class="comment">#numpy.savetxt('wh23_file.csv',Net.wh23_,fmt='%f')</span></span><br><span class="line">	numpy.savetxt(<span class="string">'who_file.csv'</span>,Net.who_,fmt=<span class="string">'%f'</span>)</span><br></pre></td></tr></table></div></figure>
 <font face="黑体" size="3px" color="green"> network_test.py </font>

<figure class="highlight python"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> neural_network <span class="keyword">as</span> nk</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> scipy.special</span><br><span class="line"><span class="keyword">import</span> scipy.ndimage.interpolation</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> progressbar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试神经网络</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">	input_nodes = nk.input_nodes</span><br><span class="line">	hidden_nodes = nk.hidden_nodes</span><br><span class="line">	hidden_nodes_2 = nk.hidden_nodes_2</span><br><span class="line">	<span class="comment">#hidden_nodes_3 = nk.hidden_nodes_3</span></span><br><span class="line">	output_nodes = nk.output_nodes</span><br><span class="line">	learningrate = nk.learningrate</span><br><span class="line">	Network = nk.neuralNetwork(input_nodes,hidden_nodes,hidden_nodes_2,output_nodes,learningrate)</span><br><span class="line">	nk.test(Network,<span class="string">"mnist_test.csv"</span>)</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line"><span class="comment"># hidden_nodes = 200 lr = 0.01 performance = 97.34</span></span><br></pre></td></tr></table></div></figure>
<hr>

        <h4 id="运行程序">
          <a href="#运行程序" class="heading-link"><i class="fas fa-link"></i></a>运行程序</h4>
      <ol>
<li>cd进入代码所在文件夹</li>
<li>(训练神经网络)输入命令：<font color="green" face="黑体">python</font> <font color="blue" face="黑体">neural_network.py</font></li>
</ol>
<p><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607011216578.png" alt="Training"></p>
<ol start="3">
<li>（测试神经网络）输入命令：<font color="green" face="黑体">python</font> <font color="blue" face="黑体">network_test.py</font></li>
</ol>
<p><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89/20190607011510082.png" alt="Testing"></p>
<font size="1px" color="red">[Warning] 运行时请确保训练集和测试集数据的.csv文件与源代码文件在同一个目录下，否则请修改源码中的文件路径</font></div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://www.ccyh.xyz">Liam</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://www.ccyh.xyz/p/e173.html">https://www.ccyh.xyz/p/e173.html</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://www.ccyh.xyz/tags/ML/">ML</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/p/ebe8.html"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">深度学习-卷积神经网络(0)</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/p/1d72.html"><span class="paginator-prev__text">人工神经网络学习笔记（2）</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Python-numpy编码实现人工神经网络"><span class="toc-number">1.</span> <span class="toc-text">
          Python-numpy编码实现人工神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#准备数据："><span class="toc-number">1.1.</span> <span class="toc-text">
          准备数据：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#编码实现"><span class="toc-number">1.2.</span> <span class="toc-text">
          编码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#运行程序"><span class="toc-number">1.3.</span> <span class="toc-text">
          运行程序</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">47</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">11</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">21</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Liam</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v3.8.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.0.0-rc.0</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zindex="-1"></script><script src="/js/utils.js?v=2.0.0-rc.0"></script><script src="/js/stun-boot.js?v=2.0.0-rc.0"></script><script src="/js/scroll.js?v=2.0.0-rc.0"></script><script src="/js/header.js?v=2.0.0-rc.0"></script><script src="/js/sidebar.js?v=2.0.0-rc.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>