<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.0.0-rc.0" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.0.0-rc.0" type="image/png" sizes="32x32"><meta name="description" content="何为人工神经网络       人工神经网络是模拟人脑的神经网络，用以实现人工智能的机器学习技术。我们知道，人脑可以说是世界上最复杂最精妙的系统之一，它由千亿计的神经元细胞组成。各个神经细胞相互链接，彼此之间传递电信号。从而造就了人类高于其他物种的思维能力。科学家受到人脑神经元的启发从而提出了人工神经网络的设想，使得人工智能的实现不再遥不可及。">
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="人工神经网络学习笔记（0）">
<meta property="og:url" content="https://www.ccyh.xyz/p/a573.html">
<meta property="og:site_name" content="Liam&#39;s Blog">
<meta property="og:description" content="何为人工神经网络       人工神经网络是模拟人脑的神经网络，用以实现人工智能的机器学习技术。我们知道，人脑可以说是世界上最复杂最精妙的系统之一，它由千亿计的神经元细胞组成。各个神经细胞相互链接，彼此之间传递电信号。从而造就了人类高于其他物种的思维能力。科学家受到人脑神经元的启发从而提出了人工神经网络的设想，使得人工智能的实现不再遥不可及。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2877951112,4239204535&fm=26&gp=0.jpg">
<meta property="og:image" content="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=1784596280,2741805283&fm=26&gp=0.jpg">
<meta property="og:image" content="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=2160826125,3899173269&fm=26&gp=0.jpg">
<meta property="og:image" content="https://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/model.jpeg">
<meta property="og:image" content="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=266571296,2744303426&fm=26&gp=0.jpg">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023656961.png">
<meta property="og:image" content="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023612835.png">
<meta property="og:updated_time" content="2020-03-23T04:59:32.937Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工神经网络学习笔记（0）">
<meta name="twitter:description" content="何为人工神经网络       人工神经网络是模拟人脑的神经网络，用以实现人工智能的机器学习技术。我们知道，人脑可以说是世界上最复杂最精妙的系统之一，它由千亿计的神经元细胞组成。各个神经细胞相互链接，彼此之间传递电信号。从而造就了人类高于其他物种的思维能力。科学家受到人脑神经元的启发从而提出了人工神经网络的设想，使得人工智能的实现不再遥不可及。">
<meta name="twitter:image" content="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2877951112,4239204535&fm=26&gp=0.jpg"><meta name="keywords" content="Liam, Liam's Blog"><meta name="description" content="Algorithms"><title>人工神经网络学习笔记（0）</title><link ref="canonical" href="/p/a573.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.0.0-rc.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Liam's Blog</div><div class="header-banner-info__subtitle">Liam's blog</div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">人工神经网络学习笔记（0）</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2019-06-03</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2020-03-23</span></span></div></header><div class="post-body"><hr>

        <!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 id="何为人工神经网络">
          <a href="#何为人工神经网络" class="heading-link"><i class="fas fa-link"></i></a>何为人工神经网络</h2>
      <p>人工神经网络是模拟人脑的神经网络，用以实现人工智能的机器学习技术。我们知道，人脑可以说是世界上最复杂最精妙的系统之一，它由千亿计的神经元细胞组成。各个神经细胞相互链接，彼此之间传递电信号。从而造就了人类高于其他物种的思维能力。科学家受到人脑神经元的启发从而提出了人工神经网络的设想，使得人工智能的实现不再遥不可及。<br><a id="more"></a></p>

        <h2 id="生物神经元">
          <a href="#生物神经元" class="heading-link"><i class="fas fa-link"></i></a>生物神经元</h2>
      <p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2877951112,4239204535&amp;fm=26&amp;gp=0.jpg" alt=""><br><strong>关键部件：</strong> 树突 &amp; 胞体 &amp; 轴突</p>
<ul>
<li>单个神经元的工作机制可以简单地描述为：树突接受其他神经元的神经末梢传来的电信号，信号传送到胞体并由某种机制决定是否激发下一次电信号的传递，若激发则电信号由轴突传递至神经末梢，再由神经末梢传递给其他神经元。其中，判断是否激发的机制有一大好处是可以减小神经元间微弱电信号（噪声）的干扰，使得自由足够强的电信号才能激发下一次传递。</li>
</ul>

        <h2 id="人工神经元">
          <a href="#人工神经元" class="heading-link"><i class="fas fa-link"></i></a>人工神经元</h2>
      
        <h3 id="概览">
          <a href="#概览" class="heading-link"><i class="fas fa-link"></i></a>概览</h3>
      <p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=1784596280,2741805283&amp;fm=26&amp;gp=0.jpg" alt="人工神经元"></p>
<ul>
<li>由生物神经元得到的启发，人工神经元与其大同小异。上图中： $x_1,x_2,x_3,x_4$ 为该神经元树突所接受到的其他神经元传来的电信号。中间的圆圈为胞体，在胞体中将会由处理信号的机制，以决定输出信号y。
        <h3 id="功能">
          <a href="#功能" class="heading-link"><i class="fas fa-link"></i></a>功能</h3>
      </li>
<li>在之前的生物神经元中已经说道，神经元对是否激发信号传递有一个判断机制，这是因为神经元不希望传递微小的噪声信号，而只传递有意识的明显信号。只有信号强度达到了某一个阙值，才会激发电信号的传递。<br><strong>那么在人工神经元中我们如何来实现这个机制呢？</strong></li>
<li>这样的一个函数也许能够满足我们的需要：<br>$$Function(x) = \begin{cases}<br>0 &amp; x \leq T \\<br>1 &amp; x&gt;T<br>\end{cases}$$<br>显而易见，这个简单的阶跃函数在输入信号大于T（阙值）时才会产生输出信号1（被激发），而较小的输入时输出为0（被抑制）；我们称这样的函数为激活函数。当然，激活函数不会就只有这么一种。常用的还有sigmoid函数：<br>$$Sigmoid(x) = \frac{1}{1+e^{-x}}$$<br>函数图像：<br><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=2160826125,3899173269&amp;fm=26&amp;gp=0.jpg" alt=""><br>可以发现，sigmoid函数相对于阶跃函数而言更加平滑，自然，接近现实。我们的神经网络也将采用它。<br>如此一来，我们的单个神经元模型就成型了：<br><img src="https://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/model.jpeg" alt="人工神经元模型"><br>参数含义：</li>
<li>$x_1 ,x_2… x_m$为输入信号</li>
<li>$w_1 ,w_2… w_m$为权重值，表示各个输入信号对输出结果的影响力大小。对于为何引入权值可以做如下思考：你去相亲，你对未来对象的考量主要有身高，长相，身材，文化程度等，但遇到样样都好的概率实在是太底了，所以你决定适当放宽某些要求。比如如果学历高就可以降低身材长相的要求。这表示你比较注重伴侣的文化程度。因此，对方的文化程度对你的择偶有着重要的影响，其所占权重就会比较高。</li>
<li>求和函数将计算$x=\sum_{m}{x_iw_i},i=1,2,…m$后将所得的值传给激活函数Sigmoid即：<br>$$Output=Sig(x)=\frac{1}{1+e^{-(\sum_{m}{x_iw_i})}}$$<br>观察函数图不难发现，Sigmoid函数将加权求和的输入映射到0~1的值域内输出。
        <h2 id="人工神经网络">
          <a href="#人工神经网络" class="heading-link"><i class="fas fa-link"></i></a>人工神经网络</h2>
      <img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=266571296,2744303426&amp;fm=26&amp;gp=0.jpg" alt=""><br>介绍完单个神经元的功能，如果把这些小部件组合起来，就成了所谓的人工神经网络。<br><strong>层次结构：</strong></li>
<li>输入层：接受外部输入信息，可以是图片等。</li>
<li>隐藏层：隐藏层层数不一，可根据需求来定。</li>
<li>输出层：将结果输出到外部。</li>
</ul>
<p><strong>链接方式：</strong></p>
<ul>
<li>除输入层外，每一层的每个神经元都接受其上一层所有神经元传来的信号的加权值。</li>
<li>神经元的链接方式并不唯一，你可以创造自己的链接方式，但为了便于抽象计算编码，规则的链接方式能帮我们大忙。</li>
</ul>

        <h3 id="一个三层神经网络示例">
          <a href="#一个三层神经网络示例" class="heading-link"><i class="fas fa-link"></i></a>一个三层神经网络示例</h3>
      <p><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023656961.png" alt=""></p>
<hr>
<p><strong>参数释义：</strong></p>
<ul>
<li>$i_1,i_2,i_3$为输入信号。</li>
<li>$w_{j,k}$表示后层结点$j$与前一层节点$k$之间链接的权重值。</li>
<li>$o_1,o_2,o_3$为该网络输出的结果信号。</li>
</ul>
<hr>
<p><strong>信号的前向传播：</strong><br>前面我们介绍了单个人工神经元对信号的处理。但是现在网络中有多个神经元，我们当然不愿意对每一个神经元节点都进行编码计算，因此我们将其简化为矩阵运算。<br><img src="http://hexoblog-1257022783.cos.ap-chengdu.myqcloud.com/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%880%EF%BC%89/20190603023612835.png" alt=""></p>
<ol>
<li>将输入看成一个多维列向量：<br>$$<br>I=<br>\left[<br>\begin{matrix}<br>i_1 \\<br>i_2 \\<br>i_3<br>\end{matrix} \right]<br>$$</li>
<li>链接权重为一个$3\times3$的矩阵：<br>$$<br>W_{input\rightarrow hidden}=<br>\left[<br>\begin{matrix}<br>w_{1,1} &amp; w_{2,1} &amp; w_{3,1} \\<br>w_{1,2} &amp; w_{2,2} &amp; w_{3,2} \\<br>w_{1,3} &amp; w_{2,3} &amp; w_{3,3}<br>\end{matrix} \right]<br>$$</li>
<li>将两者相乘得到隐藏层的输入信号：<br>$$<br>I_{hidden}=W_{input\rightarrow hidden}\cdot I=<br>\left[<br>\begin{matrix}<br>w_{1,1}\cdot i_1 + w_{2,1}\cdot i_2 + w_{3,1}\cdot i_3 \\<br>w_{1,2}\cdot i_1 + w_{2,2}\cdot i_2 + w_{3,2}\cdot i_3 \\<br>w_{1,3}\cdot i_1 + w_{2,3}\cdot i_2 + w_{3,3}\cdot i_3<br>\end{matrix} \right]<br>$$<br>也即：<br>$$<br>I_{hidden}=<br>\left[<br>\begin{matrix}<br>\sum_{j=1}^{3}{w_{j,1}\cdot i_j} \\<br>\sum_{j=1}^{3}{w_{j,2}\cdot i_j} \\<br>\sum_{j=1}^{3}{w_{j,3}\cdot i_j}<br>\end{matrix}\right]=[i_{h1},i_{h2},i_{h3}]^T<br>$$</li>
<li>再将加权求和的信号值经过Sigmoid激活函数处理我们可以得到最终的输出向量：<br>$$<br>O_{hidden}=Sig(W_{hidden\rightarrow output}\cdot I_{hidden})=<br>\left[<br>\begin{matrix}<br>Sig(\sum_{j=1}^{3}{w_{j,1}\cdot o_{hj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,2}\cdot o_{hj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,3}\cdot o_{hj}}) \\<br>\end{matrix}<br>\right]=[o_{h1},o_{h2},o_{h3}]^T<br>$$<br>这里需要注意的是，输入层到隐藏层的链接权重矩阵与隐藏层到输出成的链接权重矩阵是不同的矩阵。但是计算过程是一致的，因此同理可得：<br>$$<br>I_{output}=Sig(W_{hidden\rightarrow output}\cdot O_{hidden})<br>$$<br>网络的最终输出为：<br>$$<br>O_{output}=<br>\left[<br>\begin{matrix}<br>Sig(\sum_{j=1}^{3}{w_{j,1}\cdot i_{oj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,2}\cdot i_{oj}}) \\<br>Sig(\sum_{j=1}^{3}{w_{j,3}\cdot i_{oj}}) \\<br>\end{matrix}<br>\right]=[o_1,o_2,o_3]^T<br>$$<br>到此，我们已经了解了神经网络中信号的前向传播机制，但是目前这个网络模型远远达不到我们的要求，它除了单纯的传播信号什么事情也做不了。显然后续我们得为其添加反馈机制，使其能够具有学习能力。</li>
</ol>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://www.ccyh.xyz">Liam</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://www.ccyh.xyz/p/a573.html">https://www.ccyh.xyz/p/a573.html</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://www.ccyh.xyz/tags/ML/">ML</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/p/5972.html"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">人工神经网络学习笔记（1）</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/p/30ad.html"><span class="paginator-prev__text">感知机与逻辑门的实现</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#何为人工神经网络"><span class="toc-number">1.</span> <span class="toc-text">
          何为人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#生物神经元"><span class="toc-number">2.</span> <span class="toc-text">
          生物神经元</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经元"><span class="toc-number">3.</span> <span class="toc-text">
          人工神经元</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#概览"><span class="toc-number">3.1.</span> <span class="toc-text">
          概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#功能"><span class="toc-number">3.2.</span> <span class="toc-text">
          功能</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经网络"><span class="toc-number">4.</span> <span class="toc-text">
          人工神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#一个三层神经网络示例"><span class="toc-number">4.1.</span> <span class="toc-text">
          一个三层神经网络示例</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">47</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">11</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">21</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Liam</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v3.8.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.0.0-rc.0</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zindex="-1"></script><script src="/js/utils.js?v=2.0.0-rc.0"></script><script src="/js/stun-boot.js?v=2.0.0-rc.0"></script><script src="/js/scroll.js?v=2.0.0-rc.0"></script><script src="/js/header.js?v=2.0.0-rc.0"></script><script src="/js/sidebar.js?v=2.0.0-rc.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>